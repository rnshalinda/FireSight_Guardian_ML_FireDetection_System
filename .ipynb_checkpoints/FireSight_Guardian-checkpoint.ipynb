{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408cf0f-03cf-42ab-a668-c441d7770c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /content/\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "import torch\n",
    "train_5 = torch.hub.load('ultralytics/yolov5', 'custom', path='FD_model.pt', force_reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b1840a-5840-4197-9375-a62bc79ef158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Path to the local YOLOv5 repository\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "\n",
    "# Load the model from the local repository\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e8632-e5a7-4bde-acc7-4ea2192b4c89",
   "metadata": {},
   "source": [
    "IP check code [ also in CMD : arp -a ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b181873-55cd-4ea5-b65d-4cdadfa4604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device found: 192.168.45.57\n",
      "Device found: 192.168.45.70\n",
      "Device found: 192.168.45.125\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "import struct\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def get_ip():\n",
    "    hostname = socket.gethostname()\n",
    "    ip_address = socket.gethostbyname(hostname)\n",
    "    return ip_address\n",
    "\n",
    "def ping_ip(ip):\n",
    "    param = '-n' if platform.system().lower() == 'windows' else '-c'\n",
    "    command = ['ping', param, '1', ip]\n",
    "    response = os.popen(' '.join(command)).read()\n",
    "    if \"TTL\" in response:\n",
    "        print(f\"Device found: {ip}\")\n",
    "\n",
    "def scan_network():\n",
    "    ip_parts = get_ip().split('.')\n",
    "    base_ip = '.'.join(ip_parts[:3]) + '.'\n",
    "\n",
    "    threads = []\n",
    "    for i in range(1, 255):\n",
    "        ip = base_ip + str(i)\n",
    "        thread = threading.Thread(target=ping_ip, args=(ip,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        time.sleep(0.01)  # Small delay to prevent overwhelming the network\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scan_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912b1bf-d409-4240-ad5c-ebddf2ceb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeTECTION WITH PUSHOVER ALERT, LOW LAG (LIVE VID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d31707-e939-42ac-8ee4-e58245907aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# Pushover configuration\n",
    "pushover_user_key = 'u941tska1919u33qqxarj2qkzwz6bi'\n",
    "pushover_api_token = 'ain2jdhc8ymc34ad6kyficuvjt8n47'\n",
    "\n",
    "# Function to send Pushover notification\n",
    "def send_pushover_notification(message, image_path=None):\n",
    "    data = {\n",
    "        'token': pushover_api_token,\n",
    "        'user': pushover_user_key,\n",
    "        'message': message,\n",
    "    }\n",
    "    if image_path:\n",
    "        files = {'attachment': open(image_path, 'rb')}\n",
    "        response = requests.post('https://api.pushover.net/1/messages.json', data=data, files=files)\n",
    "    else:\n",
    "        response = requests.post('https://api.pushover.net/1/messages.json', data=data)\n",
    "    return response\n",
    "\n",
    "# Function to perform inference on a frame\n",
    "def perform_inference(frame):\n",
    "    # Perform inference (replace with your actual inference function)\n",
    "    results = train_5(frame)\n",
    "    results.render()  # Draw the results on the frame\n",
    "    return results\n",
    "\n",
    "# URL to fetch the video stream from\n",
    "video_url = 'http://192.168.90.70/'  # Replace with your ESP32-CAM stream URL\n",
    "\n",
    "# Directory to save images locally\n",
    "save_dir = 'imgs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Open the video stream\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Unable to open video stream from URL {video_url}\")\n",
    "else:\n",
    "    print(\"Video stream opened successfully!\")\n",
    "\n",
    "# Create a separate window to display the video\n",
    "cv2.namedWindow('Video Stream', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Video Stream', 480, 320)\n",
    "\n",
    "last_saved_time = time.time()\n",
    "alert_sent = False\n",
    "\n",
    "frame_buffer = []\n",
    "buffer_lock = threading.Lock()\n",
    "\n",
    "# Function to read frames from the video stream\n",
    "def read_frames():\n",
    "    global frame_buffer\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Error: Unable to read frame from URL {video_url}\")\n",
    "            break\n",
    "        with buffer_lock:\n",
    "            if len(frame_buffer) < 2:  # Buffer size of 2 to reduce latency\n",
    "                frame_buffer.append(frame)\n",
    "\n",
    "# Start a thread to read frames\n",
    "threading.Thread(target=read_frames, daemon=True).start()\n",
    "\n",
    "while True:\n",
    "    # Get the latest frame from the buffer\n",
    "    with buffer_lock:\n",
    "        if len(frame_buffer) > 0:\n",
    "            frame = frame_buffer.pop(0)\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "    # Convert the frame to RGB as needed for most models\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform inference on the frame\n",
    "    results = perform_inference(frame_rgb)\n",
    "\n",
    "    # Check if there are any detections in the results\n",
    "    detections = results.xyxy[0]  # Adjust this line based on your detection results structure\n",
    "\n",
    "    # Filter detections by confidence score\n",
    "    high_conf_detections = [d for d in detections if d[4] > 0.60]  # Assuming d[4] is the confidence score\n",
    "\n",
    "    if len(high_conf_detections) > 0:  # If there are high confidence detections\n",
    "        current_time = time.time()\n",
    "        if current_time - last_saved_time >= 1:  # Save one frame per second\n",
    "            # Convert the frame with results to BGR (OpenCV uses BGR by default)\n",
    "            frame_with_results = results.ims[0]\n",
    "            \n",
    "            # Save the frame with detections\n",
    "            timestamp = int(current_time)\n",
    "            save_path = os.path.join(save_dir, f'image_{timestamp}.jpg')\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "            print(f\"High confidence detection made! Frame saved to {save_path}\")\n",
    "\n",
    "            # Send Pushover alert\n",
    "            if not alert_sent:\n",
    "                send_pushover_notification('High confidence detection made!', save_path)\n",
    "                print('Alert notification sent!')\n",
    "                alert_sent = True\n",
    "\n",
    "            last_saved_time = current_time\n",
    "    else:\n",
    "        alert_sent = False  # Reset alert status if no high confidence detections\n",
    "        # If no detections, use the frame without results for display\n",
    "        frame_with_results = frame\n",
    "\n",
    "    # Display the frame in the separate window\n",
    "    cv2.imshow('Video Stream', frame_with_results)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Process terminated by user.\")\n",
    "        break\n",
    "\n",
    "    # Small delay to control the frame rate\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video stream closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5245b-24e7-4055-9d1b-ec96e9d59f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO ALERT DETECTION ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1f043-a00c-4fa3-b7bd-a1a42edf60ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "High confidence detection made! Frame saved to imgs\\image_1718706996.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# Function to perform inference on a frame\n",
    "def perform_inference(frame):\n",
    "    # Perform inference (replace with your actual inference function)\n",
    "    results = train_5(frame)\n",
    "    results.render()  # Draw the results on the frame\n",
    "    return results\n",
    "\n",
    "# URL to fetch the video stream from\n",
    "video_url = 'http://192.168.150.70/'  # Replace with your ESP32-CAM stream URL\n",
    "\n",
    "# Directory to save images locally\n",
    "save_dir = 'imgs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Open the video stream\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Unable to open video stream from URL {video_url}\")\n",
    "else:\n",
    "    print(\"Video stream opened successfully!\")\n",
    "\n",
    "# Create a separate window to display the video\n",
    "cv2.namedWindow('Video Stream', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Video Stream', 480, 320)\n",
    "\n",
    "last_saved_time = time.time()\n",
    "alert_sent = False\n",
    "\n",
    "frame_buffer = []\n",
    "buffer_lock = threading.Lock()\n",
    "\n",
    "# Function to read frames from the video stream\n",
    "def read_frames():\n",
    "    global frame_buffer\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Error: Unable to read frame from URL {video_url}\")\n",
    "            break\n",
    "        with buffer_lock:\n",
    "            if len(frame_buffer) < 2:  # Buffer size of 2 to reduce latency\n",
    "                frame_buffer.append(frame)\n",
    "\n",
    "# Start a thread to read frames\n",
    "threading.Thread(target=read_frames, daemon=True).start()\n",
    "\n",
    "while True:\n",
    "    # Get the latest frame from the buffer\n",
    "    with buffer_lock:\n",
    "        if len(frame_buffer) > 0:\n",
    "            frame = frame_buffer.pop(0)\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "    # Convert the frame to RGB as needed for most models\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform inference on the frame\n",
    "    results = perform_inference(frame_rgb)\n",
    "\n",
    "    # Check if there are any detections in the results\n",
    "    detections = results.xyxy[0]  # Adjust this line based on your detection results structure\n",
    "\n",
    "    # Filter detections by confidence score\n",
    "    high_conf_detections = [d for d in detections if d[4] > 0.60]  # Assuming d[4] is the confidence score\n",
    "\n",
    "    if len(high_conf_detections) > 0:  # If there are high confidence detections\n",
    "        current_time = time.time()\n",
    "        if current_time - last_saved_time >= 1:  # Save one frame per second\n",
    "            # Convert the frame with results to BGR (OpenCV uses BGR by default)\n",
    "            frame_with_results = results.ims[0]\n",
    "            \n",
    "            # Save the frame with detections\n",
    "            timestamp = int(current_time)\n",
    "            save_path = os.path.join(save_dir, f'image_{timestamp}.jpg')\n",
    "            cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "            print(f\"High confidence detection made! Frame saved to {save_path}\")\n",
    "\n",
    "            alert_sent = True\n",
    "\n",
    "            last_saved_time = current_time\n",
    "    else:\n",
    "        alert_sent = False  # Reset alert status if no high confidence detections\n",
    "        # If no detections, use the frame without results for display\n",
    "        frame_with_results = frame\n",
    "\n",
    "    # Display the frame in the separate window\n",
    "    cv2.imshow('Video Stream', frame_with_results)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Process terminated by user.\")\n",
    "        break\n",
    "\n",
    "    # Small delay to control the frame rate\n",
    "    time.sleep(0.05)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Video stream closed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca976b16-26e8-4bfa-a8c7-55bbc45c1cf3",
   "metadata": {},
   "source": [
    "FSG_App v1.0\n",
    "\n",
    "- ALERT sent YES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc7e4e-67a2-4cc1-a2ec-5cd349c4fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "High confidence detection made! Frame saved to imgs\\image_1718724184.jpg\n",
      "Alert notification sent!\n",
      "High confidence detection made! Frame saved to imgs\\image_1718724195.jpg\n",
      "Alert notification sent!\n",
      "High confidence detection made! Frame saved to imgs\\image_1718724196.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Pushover configuration\n",
    "pushover_user_key = 'u941tska1919u33qqxarj2qkzwz6bi'\n",
    "pushover_api_token = 'ain2jdhc8ymc34ad6kyficuvjt8n47'\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.alert_sent = False\n",
    "        self.running = False\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        threading.Thread(target=self.read_frames, daemon=True).start()\n",
    "        self.process_frames()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                break\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) < 2:\n",
    "                    self.frame_buffer.append(frame)\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def send_pushover_notification(self, message, image_path=None):\n",
    "        data = {\n",
    "            'token': pushover_api_token,\n",
    "            'user': pushover_user_key,\n",
    "            'message': message,\n",
    "        }\n",
    "        if image_path:\n",
    "            files = {'attachment': open(image_path, 'rb')}\n",
    "            response = requests.post('https://api.pushover.net/1/messages.json', data=data, files=files)\n",
    "        else:\n",
    "            response = requests.post('https://api.pushover.net/1/messages.json', data=data)\n",
    "        return response\n",
    "\n",
    "    def process_frames(self):\n",
    "        while self.running:\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) > 0:\n",
    "                    frame = self.frame_buffer.pop(0)\n",
    "                else:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.perform_inference(frame_rgb)\n",
    "            detections = results.xyxy[0]\n",
    "            high_conf_detections = [d for d in detections if d[4] > 0.60]\n",
    "\n",
    "            if len(high_conf_detections) > 0:\n",
    "                current_time = time.time()\n",
    "                if current_time - self.last_saved_time >= 1:\n",
    "                    frame_with_results = results.ims[0]\n",
    "                    timestamp = int(current_time)\n",
    "                    save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                    print(f\"High confidence detection made! Frame saved to {save_path}\")\n",
    "\n",
    "                    if not self.alert_sent:\n",
    "                        self.send_pushover_notification('High confidence detection made!', save_path)\n",
    "                        print('Alert notification sent!')\n",
    "                        self.alert_sent = True\n",
    "\n",
    "                    self.last_saved_time = current_time\n",
    "            else:\n",
    "                self.alert_sent = False\n",
    "                frame_with_results = frame\n",
    "\n",
    "            cv2.imshow('Video Stream', frame_with_results)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.stop_video_stream()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "# GUI Implementation\n",
    "class AppGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian Stream\")\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        tk.Label(root, text=\"ESP32-CAM Stream URL:\").pack()\n",
    "        self.url_entry = tk.Entry(root, width=50)\n",
    "        self.url_entry.pack()\n",
    "        self.url_entry.insert(0, \"http://192.168.150.70/\")\n",
    "\n",
    "        self.start_button = tk.Button(root, text=\"Start Stream\", command=self.start_stream)\n",
    "        self.start_button.pack()\n",
    "\n",
    "        self.stop_button = tk.Button(root, text=\"Stop Stream\", command=self.stop_stream)\n",
    "        self.stop_button.pack()\n",
    "\n",
    "    def start_stream(self):\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AppGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee5b9d-2bfa-44d1-84f8-139c4a7ab1f9",
   "metadata": {},
   "source": [
    "FSG_App v1.1  \n",
    "\n",
    "- ALERT sent NO\n",
    "- flame location tracking\n",
    "- no redundent images\n",
    "- 30s delay if its the same fire\n",
    "- Preview window only display last snap,  live vid runs in backround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9daeb970-0bce-4a4d-a192-c6451bd0b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1718729767.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729797.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729817.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729824.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729826.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729831.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729832.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729836.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718729842.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\NSR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"D:\\ML\\VEn_torch_cu118\\virt\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\NSR\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\NSR\\AppData\\Local\\Temp\\ipykernel_25248\\2370007626.py\", line 54, in read_frames\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        threading.Thread(target=self.read_frames, daemon=True).start()\n",
    "        self.process_frames()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                break\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) < 2:\n",
    "                    self.frame_buffer.append(frame)\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        while self.running:\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) > 0:\n",
    "                    frame = self.frame_buffer.pop(0)\n",
    "                else:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.perform_inference(frame_rgb)\n",
    "            detections = results.xyxy[0]\n",
    "            high_conf_detections = [d for d in detections if d[4] > 0.60]\n",
    "\n",
    "            for detection in high_conf_detections:\n",
    "                if self.is_new_fire_detection(detection):\n",
    "                    frame_with_results = results.ims[0]\n",
    "                    current_time = time.time()\n",
    "                    timestamp = int(current_time)\n",
    "                    save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                    print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                    self.last_saved_time = current_time\n",
    "                    self.last_detection = (*detection[:4], current_time)\n",
    "\n",
    "            cv2.imshow('Video Stream', frame_with_results if 'frame_with_results' in locals() else frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.stop_video_stream()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "# GUI Implementation\n",
    "class AppGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YOLOv5 Video Stream\")\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        tk.Label(root, text=\"ESP32-CAM Stream URL:\").pack()\n",
    "        self.url_entry = tk.Entry(root, width=50)\n",
    "        self.url_entry.pack()\n",
    "        self.url_entry.insert(0, \"http://192.168.150.70/\")\n",
    "\n",
    "        self.start_button = tk.Button(root, text=\"Start Stream\", command=self.start_stream)\n",
    "        self.start_button.pack()\n",
    "\n",
    "        self.stop_button = tk.Button(root, text=\"Stop Stream\", command=self.stop_stream)\n",
    "        self.stop_button.pack()\n",
    "\n",
    "    def start_stream(self):\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AppGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d64367e-27a9-42df-a7d4-26fe094415d0",
   "metadata": {},
   "source": [
    "FSG_App v1.2\n",
    "\n",
    "- ALERT sent NO\n",
    "- flame location tracking\n",
    "- no redundent images\n",
    "- 30s delay if its the fire in same location\n",
    "- Preview live vid\n",
    "- change confidance 40< %\n",
    "- double fire detection, If 1 fire in same location another fire starts \n",
    "\n",
    "\n",
    "fix\n",
    "- GUI\n",
    "- Stop sbutton\n",
    "- overlap multi save issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4184ec-998f-4302-bc6d-3f918729fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1718771247.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771268.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771271.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771271.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771300.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771328.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771353.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771385.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771419.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771423.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771456.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771457.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771463.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771494.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771505.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771519.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771520.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718771522.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        threading.Thread(target=self.read_frames, daemon=True).start()\n",
    "        self.process_frames()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                break\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) < 2:\n",
    "                    self.frame_buffer.append(frame)\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        while self.running:\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) > 0:\n",
    "                    frame = self.frame_buffer.pop(0)\n",
    "                else:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.perform_inference(frame_rgb)\n",
    "            detections = results.xyxy[0]\n",
    "            high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidance threshold\n",
    "\n",
    "            # Initialize frame_with_results to current frame for default display\n",
    "            frame_with_results = frame_rgb.copy()\n",
    "\n",
    "            for detection in high_conf_detections:\n",
    "                if self.is_new_fire_detection(detection):\n",
    "                    frame_with_results = results.ims[0]\n",
    "                    current_time = time.time()\n",
    "                    timestamp = int(current_time)\n",
    "                    save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                    print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                    self.last_saved_time = current_time\n",
    "                    self.last_detection = (*detection[:4], current_time)\n",
    "\n",
    "            cv2.imshow('Video Stream', cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.stop_video_stream()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "# GUI Implementation\n",
    "class AppGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YOLOv5 Video Stream\")\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        tk.Label(root, text=\"ESP32-CAM Stream URL:\").pack()\n",
    "        self.url_entry = tk.Entry(root, width=50)\n",
    "        self.url_entry.pack()\n",
    "        self.url_entry.insert(0, \"http://192.168.10.70/\")\n",
    "\n",
    "        self.start_button = tk.Button(root, text=\"Start Stream\", command=self.start_stream)\n",
    "        self.start_button.pack()\n",
    "\n",
    "        self.stop_button = tk.Button(root, text=\"Stop Stream\", command=self.stop_stream)\n",
    "        self.stop_button.pack()\n",
    "\n",
    "    def start_stream(self):\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AppGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71026cfc-50ae-4dde-b806-cf2694316891",
   "metadata": {},
   "source": [
    "FSG_App v1.3\n",
    "\n",
    "- ALERT sent NO\n",
    "- flame location tracking\n",
    "- no redundent frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- change detection confidance 40< %\n",
    "- double fire detection, If fire in one location and another fire starts while in delay, Ignores 30s delay\n",
    "- Combine detections Overlapping, Avoid Multiple saves for same detection\n",
    "\n",
    "\n",
    "fix\n",
    "- GUI\n",
    "- Stop sbutton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d32d0-b034-479d-8524-c7c2c207a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1718773528.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773559.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773588.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773588.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773618.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773618.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773632.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1718773634.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        threading.Thread(target=self.read_frames, daemon=True).start()\n",
    "        self.process_frames()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                break\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) < 2:\n",
    "                    self.frame_buffer.append(frame)\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        while self.running:\n",
    "            with self.buffer_lock:\n",
    "                if len(self.frame_buffer) > 0:\n",
    "                    frame = self.frame_buffer.pop(0)\n",
    "                else:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.perform_inference(frame_rgb)\n",
    "            detections = results.xyxy[0]\n",
    "            high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "            # Initialize frame_with_results to current frame for default display\n",
    "            frame_with_results = frame_rgb.copy()\n",
    "\n",
    "            new_detection_saved = False\n",
    "            for detection in high_conf_detections:\n",
    "                if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                    frame_with_results = results.ims[0]\n",
    "                    current_time = time.time()\n",
    "                    timestamp = int(current_time)\n",
    "                    save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                    print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                    self.last_saved_time = current_time\n",
    "                    self.last_detection = (*detection[:4], current_time)\n",
    "                    new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "\n",
    "            cv2.imshow('Video Stream', cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                self.stop_video_stream()\n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "\n",
    "# GUI Implementation\n",
    "class AppGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YOLOv5 Video Stream\")\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        tk.Label(root, text=\"ESP32-CAM Stream URL:\").pack()\n",
    "        self.url_entry = tk.Entry(root, width=50)\n",
    "        self.url_entry.pack()\n",
    "        self.url_entry.insert(0, \"http://192.168.10.70/\")\n",
    "\n",
    "        self.start_button = tk.Button(root, text=\"Start Stream\", command=self.start_stream)\n",
    "        self.start_button.pack()\n",
    "\n",
    "        self.stop_button = tk.Button(root, text=\"Stop Stream\", command=self.stop_stream)\n",
    "        self.stop_button.pack()\n",
    "\n",
    "    def start_stream(self):\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AppGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca3aa4-bef8-49ab-b77e-60cdfa6d84d9",
   "metadata": {},
   "source": [
    "FSG_App v1.4\n",
    "\n",
    "- ALERT sent NO\n",
    "- flame location tracking\n",
    "- no redundent frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- change detection confidance 40< %\n",
    "- Double detection, if fire in one location and another fire starts while in delay, Ignores 30s condition\n",
    "- Combine detections Overlapping, Avoid Multiple saves for same detection\n",
    "- start stop button fixed, preview windows closes well\n",
    "- kernal crashes fixed with Thread Joining\n",
    "\n",
    "fix\n",
    "- GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9506ebd-6150-4a04-bcba-5c7c1ae00848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1718868954.jpg\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "\n",
    "                cv2.imshow('Video Stream', cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    self.stop_video_stream()\n",
    "                    break\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Implementation\n",
    "class AppGUI:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"YOLOv5 Video Stream\")\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        tk.Label(root, text=\"ESP32-CAM Stream URL:\").pack()\n",
    "        self.url_entry = tk.Entry(root, width=50)\n",
    "        self.url_entry.pack()\n",
    "        self.url_entry.insert(0, \"http://192.168.38.70/\")\n",
    "\n",
    "        self.start_button = tk.Button(root, text=\"Start Stream\", command=self.start_stream)\n",
    "        self.start_button.pack()\n",
    "\n",
    "        self.stop_button = tk.Button(root, text=\"Stop Stream\", command=self.stop_stream)\n",
    "        self.stop_button.pack()\n",
    "\n",
    "    def start_stream(self):\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = AppGUI(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51deb1fe-2e61-44b6-96a9-9a8dcd480cf1",
   "metadata": {},
   "source": [
    "responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9fc4a05-e7a2-46ec-922f-57ca859756a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719903354.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903355.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903356.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903357.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903368.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903370.jpg\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_app to None\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding a label\n",
    "        Label(root, text=\"ESP32-CAM Stream URL:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry.insert(0, \"http://192.168.45.70/\")\n",
    "\n",
    "        self.start_button = Button(root, text=\"Start Stream\", font=('Arial', 14), command=self.start_stream)\n",
    "        self.start_button.grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        self.stop_button = Button(root, text=\"Stop Stream\", font=('Arial', 14), command=self.stop_stream)\n",
    "        self.stop_button.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size\n",
    "        self.preview_width = 480\n",
    "        self.preview_height = 320\n",
    "\n",
    "        self.canvas = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas.grid(row=2, column=0, columnspan=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.snapshot_canvas = Canvas(root, width=160, height=120, bg='black')\n",
    "        self.snapshot_canvas.grid(row=2, column=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=3, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        self.update_video()\n",
    "\n",
    "    def start_stream(self):\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "        self.terminal_text.insert(tk.END, \"Started video stream...\\n\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video stream...\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        if self.video_stream_app and self.video_stream_app.frame is not None:\n",
    "            frame = self.video_stream_app.frame\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            frame = cv2.resize(frame, (self.preview_width, self.preview_height))\n",
    "            photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=photo)\n",
    "            self.canvas.image = photo  # Keep a reference to avoid garbage collection\n",
    "\n",
    "            # Update snapshot canvas with last saved image if available\n",
    "            if self.video_stream_app.last_saved_image_path:\n",
    "                last_image = Image.open(self.video_stream_app.last_saved_image_path)\n",
    "                last_image.thumbnail((160, 120))\n",
    "                last_photo = ImageTk.PhotoImage(last_image)\n",
    "                self.snapshot_canvas.create_image(0, 0, anchor=tk.NW, image=last_photo)\n",
    "                self.snapshot_canvas.image = last_photo  # Keep a reference to avoid garbage collection\n",
    "\n",
    "        else:\n",
    "            # If no frame is available, show \"No Signal\" message in preview window\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "            self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No Signal\", fill='white', font=('Arial', 24))\n",
    "\n",
    "            # Clear snapshot canvas\n",
    "            self.snapshot_canvas.delete(\"all\")\n",
    "\n",
    "        # Schedule the next update after 50ms (20 frames per second)\n",
    "        self.root.after(50, self.update_video)\n",
    "\n",
    "# Run the GUI\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    # Provide the path to the background image\n",
    "    bg_image_path = \"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # Replace with your background image path\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089038ff-e597-4915-b23d-faafec4a1ae0",
   "metadata": {},
   "source": [
    "FSG_App v1.5\n",
    "\n",
    "- ALERT sent NO\n",
    "- flame location tracking\n",
    "- No redundent detecton frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- change detection confidance 40< %\n",
    "- Double detection, if fire in one location and another fire starts while in delay, Ignores 30s condition\n",
    "- Combine Overlapping frames, Avoid Multiple saves for same detection\n",
    "- start stop button fixed, preview windows closes well\n",
    "- kernal crashes fixed with Thread Joining\n",
    "- App GUI created\n",
    "- Detection and app launching more responsive\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a077b9df-ce6b-4794-93c9-8e2575765cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "Video stream closed.\n",
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719903289.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903304.jpg\n",
      "Video stream closed.\n",
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719903317.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719903342.jpg\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path=\"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # GUI backgrount image path\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_app to None\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding a label\n",
    "        Label(root, text=\"CAM Stream URL:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry.insert(0, \"http://192.168.45.70/\")\n",
    "\n",
    "        self.start_button = Button(root, text=\"Start Stream\", font=('Arial', 14), command=self.start_stream)\n",
    "        self.start_button.grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        self.stop_button = Button(root, text=\"Stop Stream\", font=('Arial', 14), command=self.stop_stream)\n",
    "        self.stop_button.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size\n",
    "        self.preview_width = 580\n",
    "        self.preview_height = 370\n",
    "\n",
    "        self.canvas = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas.grid(row=2, column=0, columnspan=2, padx=10, pady=10, sticky='n')\n",
    "        self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text = self.canvas.create_text(self.preview_width//2, self.preview_height//2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        self.snapshot_canvas = Canvas(root, width=160, height=120, bg='black')\n",
    "        self.snapshot_canvas.grid(row=2, column=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=3, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        self.update_video()\n",
    "\n",
    "    def start_stream(self):\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "        self.terminal_text.insert(tk.END, \"Started video stream...\\n\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video stream...\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        if self.video_stream_app and self.video_stream_app.frame is not None:\n",
    "            self.canvas.delete(\"all\")\n",
    "            #frame_rgb = cv2.cvtColor(self.video_stream_app.frame, cv2.COLOR_RGB2BGR)\n",
    "            frame_rgb = self.video_stream_app.frame\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_pil = frame_pil.resize((self.preview_width, self.preview_height), Image.LANCZOS)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "        else:\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "            self.canvas.create_text(self.preview_width//2, self.preview_height//2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        if self.video_stream_app and self.video_stream_app.last_saved_image_path:\n",
    "            snapshot_image = Image.open(self.video_stream_app.last_saved_image_path)\n",
    "            snapshot_image = snapshot_image.resize((160, 120), Image.LANCZOS)\n",
    "            snapshot_tk = ImageTk.PhotoImage(snapshot_image)\n",
    "            self.snapshot_canvas.create_image(0, 0, anchor=NW, image=snapshot_tk)\n",
    "            self.snapshot_canvas.image = snapshot_tk\n",
    "\n",
    "        self.root.after(30, self.update_video)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b929f64b-94c8-4054-bdbd-6a5be67c3c6d",
   "metadata": {},
   "source": [
    "FSG_App v1.6\n",
    "\n",
    "- flame location tracking\n",
    "- No redundent detecton frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- change detection confidance 40< %\n",
    "- Double detection, if fire in one location and another fire starts while in delay, Ignores 30s condition\n",
    "- Combine Overlapping frames, Avoid Multiple saves for same detection\n",
    "- start stop button fixed, preview windows closes well\n",
    "- kernal crashes fixed with Thread Joining\n",
    "- App GUI created\n",
    "- Detection and app launching more responsive\n",
    "- Pushover Notification ALERT added\n",
    "- Notification Toggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a34366b-491c-4089-a84b-6aff15cf66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719927736.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719927736.jpg\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "import requests  # for notification\n",
    "\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Pushover configuration\n",
    "pushover_user_key = 'u941tska1919u33qqxarj2qkzwz6bi'\n",
    "pushover_api_token = 'ain2jdhc8ymc34ad6kyficuvjt8n47'\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path = \"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # GUI backgrount image path\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        self.pushover_enabled = False  # Toggle for Pushover notifications\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    # PushOver Alert part\n",
    "    def send_pushover_notification(self, message, image_path=None):\n",
    "        data = {\n",
    "            'token': pushover_api_token,\n",
    "            'user': pushover_user_key,\n",
    "            'message': message,\n",
    "        }\n",
    "        if image_path:\n",
    "            files = {'attachment': open(image_path, 'rb')}\n",
    "            response = requests.post('https://api.pushover.net/1/messages.json', data=data, files=files)\n",
    "        else:\n",
    "            response = requests.post('https://api.pushover.net/1/messages.json', data=data)\n",
    "        return response\n",
    "    \n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "\n",
    "                        # Send Pushover notification if enabled\n",
    "                        if self.pushover_enabled:\n",
    "                            self.send_pushover_notification('High confidence detection made!', save_path)\n",
    "                            print('Alert notification sent!')\n",
    "                        \n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_app to None\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding a label\n",
    "        Label(root, text=\"CAM Stream URL:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry.insert(0, \"http://192.168.45.70/\")\n",
    "\n",
    "        self.start_button = Button(root, text=\"Start Stream\", font=('Arial', 14), command=self.start_stream)\n",
    "        self.start_button.grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        self.stop_button = Button(root, text=\"Stop Stream\", font=('Arial', 14), command=self.stop_stream)\n",
    "        self.stop_button.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        self.toggle_button = Button(root, text=\"Enable Notifications\", font=('Arial', 14), command=self.toggle_notifications)\n",
    "        self.toggle_button.grid(row=1, column=2, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size\n",
    "        self.preview_width = 580\n",
    "        self.preview_height = 370\n",
    "\n",
    "        self.canvas = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas.grid(row=2, column=0, columnspan=2, padx=10, pady=10, sticky='n')\n",
    "        self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text = self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        self.snapshot_canvas = Canvas(root, width=160, height=120, bg='black')\n",
    "        self.snapshot_canvas.grid(row=2, column=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=3, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        self.update_video()\n",
    "\n",
    "    def start_stream(self):\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "        self.terminal_text.insert(tk.END, \"Started video stream...\\n\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video stream...\\n\")\n",
    "\n",
    "    def toggle_notifications(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.pushover_enabled = not self.video_stream_app.pushover_enabled\n",
    "            if self.video_stream_app.pushover_enabled:\n",
    "                self.toggle_button.config(text=\"Disable Notifications\", bg='red')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications enabled.\\n\")\n",
    "            else:\n",
    "                self.toggle_button.config(text=\"Enable Notifications\", bg='white')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications disabled.\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        if self.video_stream_app and self.video_stream_app.frame is not None:\n",
    "            self.canvas.delete(\"all\")\n",
    "            #frame_rgb = cv2.cvtColor(self.video_stream_app.frame, cv2.COLOR_RGB2BGR)\n",
    "            frame_rgb = self.video_stream_app.frame\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_pil = frame_pil.resize((self.preview_width, self.preview_height), Image.LANCZOS)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "        else:\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "            self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        if self.video_stream_app and self.video_stream_app.last_saved_image_path:\n",
    "            snapshot_image = Image.open(self.video_stream_app.last_saved_image_path)\n",
    "            snapshot_image = snapshot_image.resize((160, 120), Image.LANCZOS)\n",
    "            snapshot_tk = ImageTk.PhotoImage(snapshot_image)\n",
    "            self.snapshot_canvas.create_image(0, 0, anchor=NW, image=snapshot_tk)\n",
    "            self.snapshot_canvas.image = snapshot_tk\n",
    "\n",
    "        self.root.after(30, self.update_video)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815393cf-f656-4e56-9242-c8e436cc4fbd",
   "metadata": {},
   "source": [
    "FSG_App v1.7\n",
    "\n",
    "- flame location tracking\n",
    "- No redundent detecton frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- change detection confidance 40< %\n",
    "- Double detection, if fire in one location and another fire starts while in delay, Ignores 30s condition\n",
    "- Combine Overlapping frames, Avoid Multiple saves for same detection\n",
    "- start stop button fixed, preview windows closes well\n",
    "- kernal crashes fixed with Thread Joining\n",
    "- App GUI created\n",
    "- Detection and App Launch/Close responsiveness fixed\n",
    "- Pushover Notification ALERT added\n",
    "- Notification Toggle switch added\n",
    "- Last saved images preview in scrolable window \n",
    "- Fixed the App flickering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bcbc0b-3d32-4305-b9a9-05faff864238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719930827.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719930838.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719930840.jpg\n",
      "Video stream closed.\n",
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719930888.jpg\n",
      "New fire detected! Frame saved to imgs\\image_1719930901.jpg\n",
      "Alert notification sent!\n",
      "Notification sent: 200\n",
      "New fire detected! Frame saved to imgs\\image_1719930935.jpg\n",
      "Alert notification sent!\n",
      "Notification sent: 200\n",
      "Video stream closed.\n",
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to imgs\\image_1719930954.jpg\n",
      "Alert notification sent!\n",
      "Notification sent: 200\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW, Frame, Scrollbar, VERTICAL, RIGHT, Y, LEFT, BOTH\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "import requests  # for notification\n",
    "from concurrent.futures import ThreadPoolExecutor  # for asynchronous execution\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Pushover configuration\n",
    "pushover_user_key = 'u941tska1919u33qqxarj2qkzwz6bi'\n",
    "pushover_api_token = 'ain2jdhc8ymc34ad6kyficuvjt8n47'\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path = \"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # GUI background image path\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        self.pushover_enabled = False  # Toggle for Pushover notifications\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.executor = ThreadPoolExecutor(max_workers=1)  # Thread pool for notifications\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    # PushOver Alert part\n",
    "    def send_pushover_notification(self, message, image_path=None):\n",
    "        def send_notification():\n",
    "            data = {\n",
    "                'token': pushover_api_token,\n",
    "                'user': pushover_user_key,\n",
    "                'message': message,\n",
    "            }\n",
    "            try:\n",
    "                if image_path:\n",
    "                    files = {'attachment': open(image_path, 'rb')}\n",
    "                    response = requests.post('https://api.pushover.net/1/messages.json', data=data, files=files)\n",
    "                else:\n",
    "                    response = requests.post('https://api.pushover.net/1/messages.json', data=data)\n",
    "                print(f'Notification sent: {response.status_code}')\n",
    "            except Exception as e:\n",
    "                print(f'Failed to send notification: {e}')\n",
    "        \n",
    "        # Submit notification task to thread pool executor\n",
    "        self.executor.submit(send_notification)\n",
    "    \n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "\n",
    "                        # Send Pushover notification if enabled\n",
    "                        if self.pushover_enabled:\n",
    "                            self.send_pushover_notification('High confidence detection made!', save_path)\n",
    "                            print('Alert notification sent!')\n",
    "                        \n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_app to None\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding a label\n",
    "        Label(root, text=\"CAM Stream URL:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry.insert(0, \"http://192.168.45.70/\")\n",
    "\n",
    "        self.start_button = Button(root, text=\"Start Stream\", font=('Arial', 14), command=self.start_stream)\n",
    "        self.start_button.grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        self.stop_button = Button(root, text=\"Stop Stream\", font=('Arial', 14), command=self.stop_stream)\n",
    "        self.stop_button.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        self.toggle_button = Button(root, text=\"Enable Notifications\", font=('Arial', 14), command=self.toggle_notifications)\n",
    "        self.toggle_button.grid(row=1, column=2, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size\n",
    "        self.preview_width = 580\n",
    "        self.preview_height = 370\n",
    "\n",
    "        self.canvas = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas.grid(row=2, column=0, columnspan=2, padx=10, pady=10, sticky='n')\n",
    "        self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text = self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        self.snapshot_frame = Frame(root, width=180, height=380)\n",
    "        self.snapshot_frame.grid(row=2, column=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.snapshot_canvas = Canvas(self.snapshot_frame, width=160, height=360, bg='black')\n",
    "        self.snapshot_canvas.pack(side=LEFT, fill=BOTH, expand=True)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.snapshot_frame, orient=VERTICAL, command=self.snapshot_canvas.yview)\n",
    "        self.scrollbar.pack(side=RIGHT, fill=Y)\n",
    "\n",
    "        self.snapshot_canvas.configure(yscrollcommand=self.scrollbar.set)\n",
    "        self.snapshot_canvas.bind('<Configure>', lambda e: self.snapshot_canvas.configure(scrollregion=self.snapshot_canvas.bbox('all')))\n",
    "\n",
    "        self.image_frame = Frame(self.snapshot_canvas, width=160, height=360)\n",
    "        self.snapshot_canvas.create_window((0, 0), window=self.image_frame, anchor=NW)\n",
    "\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=3, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        self.update_video()\n",
    "\n",
    "    def start_stream(self):\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "        self.terminal_text.insert(tk.END, \"Started video stream...\\n\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video stream...\\n\")\n",
    "\n",
    "    def toggle_notifications(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.pushover_enabled = not self.video_stream_app.pushover_enabled\n",
    "            if self.video_stream_app.pushover_enabled:\n",
    "                self.toggle_button.config(text=\"Disable Notifications\", bg='red')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications enabled.\\n\")\n",
    "            else:\n",
    "                self.toggle_button.config(text=\"Enable Notifications\", bg='white')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications disabled.\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        if self.video_stream_app and self.video_stream_app.frame is not None:\n",
    "            self.canvas.delete(\"all\")\n",
    "            frame_rgb = self.video_stream_app.frame\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_pil = frame_pil.resize((self.preview_width, self.preview_height), Image.LANCZOS)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "        else:\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "            self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        if self.video_stream_app:\n",
    "            self.update_snapshots()\n",
    "\n",
    "        self.root.after(30, self.update_video)\n",
    "\n",
    "    def update_snapshots(self):\n",
    "        for widget in self.image_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        for image_file in sorted(os.listdir(self.video_stream_app.save_dir), reverse=True):\n",
    "            if image_file.endswith(\".jpg\"):\n",
    "                image_path = os.path.join(self.video_stream_app.save_dir, image_file)\n",
    "                snapshot_image = Image.open(image_path)\n",
    "                snapshot_image = snapshot_image.resize((160, 120), Image.LANCZOS)\n",
    "                snapshot_tk = ImageTk.PhotoImage(snapshot_image)\n",
    "                label = Label(self.image_frame, image=snapshot_tk)\n",
    "                label.image = snapshot_tk\n",
    "                label.pack()\n",
    "\n",
    "    def clean_up(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", app.clean_up)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df8554-b10a-4769-87eb-3b27e601b335",
   "metadata": {},
   "source": [
    "double window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66c8f7d-aa77-4291-9f1e-71f65d5115e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path=\"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # GUI background image path\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40] # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_apps to None\n",
    "        self.video_stream_apps = [None, None]\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding labels and entries for both URLs\n",
    "        Label(root, text=\"ESP32-CAM Stream URL 1:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry1 = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry1.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry1.insert(0, \"http://192.168.129.70/\")\n",
    "\n",
    "        Label(root, text=\"ESP32-CAM Stream URL 2:\", font=('Arial', 14), bg='#2a9df4').grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry2 = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry2.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry2.insert(0, \"http://192.168.129.71/\")\n",
    "\n",
    "        self.start_button = Button(root, text=\"Start Streams\", font=('Arial', 14), command=self.start_streams)\n",
    "        self.start_button.grid(row=2, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        self.stop_button = Button(root, text=\"Stop Streams\", font=('Arial', 14), command=self.stop_streams)\n",
    "        self.stop_button.grid(row=2, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size\n",
    "        self.preview_width = 480\n",
    "        self.preview_height = 320\n",
    "\n",
    "        self.canvas1 = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas1.grid(row=3, column=0, padx=10, pady=10, sticky='n')\n",
    "        self.canvas1.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text1 = self.canvas1.create_text(self.preview_width//2, self.preview_height//2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        self.canvas2 = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas2.grid(row=3, column=1, padx=10, pady=10, sticky='n')\n",
    "        self.canvas2.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text2 = self.canvas2.create_text(self.preview_width//2, self.preview_height//2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        self.snapshot_canvas1 = Canvas(root, width=160, height=120, bg='black')\n",
    "        self.snapshot_canvas1.grid(row=4, column=0, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.snapshot_canvas2 = Canvas(root, width=160, height=120, bg='black')\n",
    "        self.snapshot_canvas2.grid(row=4, column=1, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=5, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        self.update_video()\n",
    "\n",
    "    def start_streams(self):\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "        video_url1 = self.url_entry1.get()\n",
    "        video_url2 = self.url_entry2.get()\n",
    "\n",
    "        self.video_stream_apps[0] = VideoStreamApp(video_url1)\n",
    "        self.video_stream_apps[1] = VideoStreamApp(video_url2)\n",
    "\n",
    "        if not self.video_stream_apps[0].start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream 1. Check the URL.\")\n",
    "        if not self.video_stream_apps[1].start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream 2. Check the URL.\")\n",
    "        self.terminal_text.insert(tk.END, \"Started video streams...\\n\")\n",
    "\n",
    "    def stop_streams(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "        for app in self.video_stream_apps:\n",
    "            if app:\n",
    "                app.stop_video_stream()\n",
    "        self.video_stream_apps = [None, None]\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video streams...\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        for i, canvas in enumerate([self.canvas1, self.canvas2]):\n",
    "            if self.video_stream_apps[i] and self.video_stream_apps[i].frame is not None:\n",
    "                canvas.delete(\"all\")\n",
    "                frame_rgb = self.video_stream_apps[i].frame\n",
    "                frame_pil = Image.fromarray(frame_rgb)\n",
    "                frame_pil = frame_pil.resize((self.preview_width, self.preview_height), Image.LANCZOS)\n",
    "                frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "                canvas.create_image(0, 0, anchor=NW, image=frame_tk)\n",
    "                canvas.image = frame_tk\n",
    "            else:\n",
    "                canvas.delete(\"all\")\n",
    "                canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "                canvas.create_text(self.preview_width//2, self.preview_height//2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "            snapshot_canvas = [self.snapshot_canvas1, self.snapshot_canvas2][i]\n",
    "            if self.video_stream_apps[i] and self.video_stream_apps[i].last_saved_image_path:\n",
    "                snapshot_image = Image.open(self.video_stream_apps[i].last_saved_image_path)\n",
    "                snapshot_image = snapshot_image.resize((160, 120), Image.LANCZOS)\n",
    "                snapshot_tk = ImageTk.PhotoImage(snapshot_image)\n",
    "                snapshot_canvas.create_image(0, 0, anchor=NW, image=snapshot_tk)\n",
    "                snapshot_canvas.image = snapshot_tk\n",
    "\n",
    "        self.root.after(30, self.update_video)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a02ae8-d959-4aa8-a60c-b098ffa7bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading background image from anna-popovic-zZkMki0yH6I-unsplash.jpg\n",
      "Background image loaded and set successfully.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "from PyQt5.QtWidgets import (QApplication, QWidget, QLabel, QPushButton, QLineEdit, QVBoxLayout, \n",
    "                             QHBoxLayout, QGridLayout, QTextEdit, QMainWindow, QGraphicsOpacityEffect)\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# Temporary change for pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "# Load YOLOv5 model\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/yolov5\"\n",
    "model = 'custom'\n",
    "path = 'FD_model.pt'\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path = \"anna-popovic-zZkMki0yH6I-unsplash.jpg\"  # GUI background image path\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, save_dir='imgs'):\n",
    "        self.video_url = video_url\n",
    "        self.save_dir = save_dir\n",
    "        self.cap = None\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_lock = threading.Lock()\n",
    "        self.last_saved_time = time.time()\n",
    "        self.last_detection = None\n",
    "        self.detection_interval = 30  # Interval in seconds\n",
    "        self.running = False\n",
    "        self.read_thread = None\n",
    "        self.process_thread = None\n",
    "        self.frame = None\n",
    "        self.last_saved_image_path = None\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    def stop_video_stream(self):\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.perform_inference(frame_rgb)\n",
    "                detections = results.xyxy[0]\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40]  # Detection confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.save_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "                        self.last_saved_time = current_time\n",
    "                        self.last_detection = (*detection[:4], current_time)\n",
    "                        new_detection_saved = True  # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results\n",
    "                time.sleep(0.05)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "class App(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(\"FireSight Guardian\")\n",
    "        self.setGeometry(100, 100, 1600, 900)\n",
    "\n",
    "        # Central widget and layout\n",
    "        central_widget = QWidget(self)\n",
    "        self.setCentralWidget(central_widget)\n",
    "        main_layout = QVBoxLayout(central_widget)\n",
    "        top_layout = QHBoxLayout()\n",
    "        stream_layout = QGridLayout()\n",
    "        snapshot_layout = QHBoxLayout()\n",
    "        terminal_layout = QVBoxLayout()\n",
    "\n",
    "        # Background image\n",
    "        self.setStyleSheet(\"background-color: black;\")\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            print(f\"Loading background image from {bg_image_path}\")\n",
    "            bg_image = Image.open(bg_image_path)\n",
    "            bg_image = bg_image.resize((self.width(), self.height()), Image.LANCZOS)\n",
    "            bg_image = bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            bg_qimage = self.pil2qimage(bg_image)\n",
    "            bg_pixmap = QPixmap.fromImage(bg_qimage)\n",
    "            bg_label = QLabel(self)\n",
    "            bg_label.setPixmap(bg_pixmap)\n",
    "            bg_label.setGeometry(0, 0, self.width(), self.height())\n",
    "            bg_label.lower()\n",
    "            bg_opacity = QGraphicsOpacityEffect()\n",
    "            bg_opacity.setOpacity(0.5)\n",
    "            bg_label.setGraphicsEffect(bg_opacity)\n",
    "            print(\"Background image loaded and set successfully.\")\n",
    "\n",
    "        # URL Inputs\n",
    "        self.url_entry1 = QLineEdit(\"http://192.168.129.70/\")\n",
    "        self.url_entry2 = QLineEdit(\"http://192.168.129.71/\")\n",
    "\n",
    "        # Start/Stop Buttons\n",
    "        self.start_button1 = QPushButton(\"Start Stream 1\")\n",
    "        self.stop_button1 = QPushButton(\"Stop Stream 1\")\n",
    "        self.start_button2 = QPushButton(\"Start Stream 2\")\n",
    "        self.stop_button2 = QPushButton(\"Stop Stream 2\")\n",
    "\n",
    "        self.start_button1.clicked.connect(lambda: self.start_stream(0))\n",
    "        self.stop_button1.clicked.connect(lambda: self.stop_stream(0))\n",
    "        self.start_button2.clicked.connect(lambda: self.start_stream(1))\n",
    "        self.stop_button2.clicked.connect(lambda: self.stop_stream(1))\n",
    "\n",
    "        # Video Canvases\n",
    "        self.video_label1 = QLabel()\n",
    "        self.video_label2 = QLabel()\n",
    "        self.video_label1.setFixedSize(640, 480)\n",
    "        self.video_label2.setFixedSize(640, 480)\n",
    "\n",
    "        # Snapshot Canvases\n",
    "        self.snapshot_label1 = QLabel()\n",
    "        self.snapshot_label2 = QLabel()\n",
    "        self.snapshot_label1.setFixedSize(320, 240)\n",
    "        self.snapshot_label2.setFixedSize(320, 240)\n",
    "\n",
    "        # Terminal\n",
    "        self.terminal_text = QTextEdit()\n",
    "        self.terminal_text.setReadOnly(True)\n",
    "\n",
    "        # Assemble Layouts\n",
    "        top_layout.addWidget(QLabel(\"ESP32-CAM Stream URL 1:\"))\n",
    "        top_layout.addWidget(self.url_entry1)\n",
    "        top_layout.addWidget(self.start_button1)\n",
    "        top_layout.addWidget(self.stop_button1)\n",
    "        top_layout.addWidget(QLabel(\"ESP32-CAM Stream URL 2:\"))\n",
    "        top_layout.addWidget(self.url_entry2)\n",
    "        top_layout.addWidget(self.start_button2)\n",
    "        top_layout.addWidget(self.stop_button2)\n",
    "\n",
    "        stream_layout.addWidget(self.video_label1, 0, 0)\n",
    "        stream_layout.addWidget(self.video_label2, 0, 1)\n",
    "\n",
    "        snapshot_layout.addWidget(self.snapshot_label1)\n",
    "        snapshot_layout.addWidget(self.snapshot_label2)\n",
    "\n",
    "        terminal_layout.addWidget(QLabel(\"Terminal Output:\"))\n",
    "        terminal_layout.addWidget(self.terminal_text)\n",
    "\n",
    "        main_layout.addLayout(top_layout)\n",
    "        main_layout.addLayout(stream_layout)\n",
    "        main_layout.addLayout(snapshot_layout)\n",
    "        main_layout.addLayout(terminal_layout)\n",
    "\n",
    "        self.video_stream_apps = [None, None]\n",
    "        self.startTimer(30)  # 30 ms\n",
    "        \n",
    "    def start_stream(self, index):\n",
    "        if self.video_stream_apps[index] is None:\n",
    "            url = self.url_entry1.text() if index == 0 else self.url_entry2.text()\n",
    "            self.video_stream_apps[index] = VideoStreamApp(url)\n",
    "            if not self.video_stream_apps[index].start_video_stream():\n",
    "                self.log_message(f\"Error: Unable to open video stream {index + 1}. Check the URL.\")\n",
    "            else:\n",
    "                self.log_message(f\"Started video stream {index + 1}.\")\n",
    "\n",
    "    def stop_stream(self, index):\n",
    "        if self.video_stream_apps[index] is not None:\n",
    "            self.video_stream_apps[index].stop_video_stream()\n",
    "            self.video_stream_apps[index] = None\n",
    "            self.log_message(f\"Stopped video stream {index + 1}.\")\n",
    "\n",
    "    def log_message(self, message):\n",
    "        current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        self.terminal_text.append(f\"[{current_time}] {message}\")\n",
    "\n",
    "    def timerEvent(self, event):\n",
    "        for i in range(2):\n",
    "            if self.video_stream_apps[i] and self.video_stream_apps[i].frame is not None:\n",
    "                frame_rgb = cv2.cvtColor(self.video_stream_apps[i].frame, cv2.COLOR_RGB2BGR)\n",
    "                frame_rgb = cv2.resize(frame_rgb, (640, 480))\n",
    "                h, w, ch = frame_rgb.shape\n",
    "                bytes_per_line = ch * w\n",
    "                q_img = QImage(frame_rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "                pixmap = QPixmap.fromImage(q_img)\n",
    "                if i == 0:\n",
    "                    self.video_label1.setPixmap(pixmap)\n",
    "                else:\n",
    "                    self.video_label2.setPixmap(pixmap)\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    self.video_label1.clear()\n",
    "                else:\n",
    "                    self.video_label2.clear()\n",
    "\n",
    "            if self.video_stream_apps[i] and self.video_stream_apps[i].last_saved_image_path:\n",
    "                snapshot_image = QPixmap(self.video_stream_apps[i].last_saved_image_path)\n",
    "                snapshot_image = snapshot_image.scaled(320, 240, Qt.KeepAspectRatio)\n",
    "                if i == 0:\n",
    "                    self.snapshot_label1.setPixmap(snapshot_image)\n",
    "                else:\n",
    "                    self.snapshot_label2.setPixmap(snapshot_image)\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    self.snapshot_label1.clear()\n",
    "                else:\n",
    "                    self.snapshot_label2.clear()\n",
    "\n",
    "    def pil2qimage(self, image):\n",
    "        image = image.convert(\"RGBA\")\n",
    "        bytes_per_line = image.width * 4\n",
    "        q_img = QImage(image.tobytes(\"raw\", \"RGBA\"), image.width, image.height, bytes_per_line, QImage.Format_RGBA8888)\n",
    "        return q_img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_window = App()\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
