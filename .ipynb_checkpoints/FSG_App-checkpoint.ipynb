{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d544ace-529d-4a74-ac0e-d3d250dd4705",
   "metadata": {},
   "source": [
    "FireSight Guardian App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aea0ab-aef9-4afd-8c91-4155e2d3932e",
   "metadata": {},
   "source": [
    "FSG_App v1.7\n",
    "\n",
    "- Flame location tracking\n",
    "- No redundent detecton frames \n",
    "- 30s delay before new capture if the fire in same location \n",
    "- Preview window live vid crash fixed\n",
    "- Change detection confidance 40< %\n",
    "- Double detection, if fire in one location and another fire starts while in delay, Ignores 30s condition\n",
    "- Combine Overlapping frames, Avoid Multiple saves for same detection\n",
    "- Start stop button fixed, preview windows closes well\n",
    "- Kernal crashes fixed with Thread Joining\n",
    "- App GUI created\n",
    "- Detection and App Launch/Close responsiveness fixed\n",
    "- Pushover Notification ALERT added\n",
    "- Notification Toggle switch added\n",
    "- Last saved images preview in scrolable window \n",
    "- Fixed the App flickering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d041ede-cc68-4d5f-868f-3878ac909cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-297-gd07d0cf6 Python-3.9.13 torch-2.2.2+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 206 layers, 12312052 parameters, 0 gradients, 16.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video stream opened successfully!\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258822.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258835.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258836.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258837.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258913.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258916.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258917.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258931.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258934.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258935.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258942.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258942.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258947.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258949.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258957.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258969.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258970.jpg\n",
      "New fire detected! Frame saved to D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs\\image_1725258974.jpg\n",
      "Video stream closed.\n"
     ]
    }
   ],
   "source": [
    "# Import Libs\n",
    "from tkinter import Tk, Label, Entry, Button, Canvas, Text, NW, Frame, Scrollbar, VERTICAL, RIGHT, Y, LEFT, BOTH\n",
    "from tkinter import messagebox\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk, ImageFilter\n",
    "import os\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import pathlib\n",
    "import torch\n",
    "import requests  # for notification\n",
    "from concurrent.futures import ThreadPoolExecutor  # for asynchronous execution\n",
    "\n",
    "# Temporary change for pathlib to work with Windows paths\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "\n",
    "# Pushover configuration (keys required for sending notifications)\n",
    "pushover_user_key = '-----'\n",
    "pushover_api_token = '-----'\n",
    "\n",
    "\n",
    "# Load the trained FD_model.pt model from the local machine\n",
    "repo_or_dir = \"D:/ML/VEn_torch_cu118/Object_Detection/yolov5\"  # Path to the Yolov5 GitHub repo cloned on local machine\n",
    "model = 'custom'\n",
    "path = \"D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/FD_model.pt\"  # FD_model.pt trained model path\n",
    "train_5 = torch.hub.load(repo_or_dir, model, source='local', path=path, force_reload=True)\n",
    "bg_image_path = \"D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/bg/flame-1363003_1920.jpg\"  # GUI bg image path\n",
    "# 'snapsave_dir' is the path to save captured detection frames\n",
    "\n",
    "class VideoStreamApp:\n",
    "    def __init__(self, video_url, snapsave_dir='D:/ML/VEn_torch_cu118/Object_Detection/Yolov5_Projects/FireSight_Guardian_ML_FireDetection_System/imgs'):\n",
    "        self.video_url = video_url            # URL of the video stream\n",
    "        self.snapsave_dir = snapsave_dir      # Directory to save snapshots\n",
    "        self.cap = None                       # Video capture object\n",
    "        self.frame_buffer = []                # Buffer to store video frames\n",
    "        self.buffer_lock = threading.Lock()   # Lock to synchronize access to the frame buffer\n",
    "        self.last_saved_time = time.time()    # Timestamp of the last saved detection frame\n",
    "        self.last_detection = None            # Last detected fire location\n",
    "        self.detection_interval = 30          # Interval between detections in seconds\n",
    "        self.running = False                  # Flag to indicate if the video stream is running\n",
    "        self.read_thread = None               # Thread for reading frames\n",
    "        self.process_thread = None            # Thread for processing frames\n",
    "        self.frame = None                     # Current frame being processed\n",
    "        self.last_saved_image_path = None     # Path of the last saved image\n",
    "        self.pushover_enabled = False         # Toggle for Pushover notifications\n",
    "        os.makedirs(snapsave_dir, exist_ok=True)           # Create directory if it doesn't exist\n",
    "        self.executor = ThreadPoolExecutor(max_workers=2)  # Thread pool for sending notifications\n",
    "\n",
    "    def start_video_stream(self):\n",
    "        # Open the video stream using OpenCV\n",
    "        self.cap = cv2.VideoCapture(self.video_url)\n",
    "        if not self.cap.isOpened():\n",
    "            print(f\"Error: Unable to open video stream from URL {self.video_url}\")\n",
    "            return False\n",
    "        print(\"Video stream opened successfully!\")\n",
    "        self.running = True\n",
    "        # Start threads for reading and processing frames\n",
    "        self.read_thread = threading.Thread(target=self.read_frames, daemon=True)\n",
    "        self.read_thread.start()\n",
    "        self.process_thread = threading.Thread(target=self.process_frames, daemon=True)\n",
    "        self.process_thread.start()\n",
    "        return True\n",
    "\n",
    "    # PushOver Alert part\n",
    "    def send_pushover_notification(self, message, image_path=None):\n",
    "        \n",
    "        def send_notification():  # Function to send a Pushover notification\n",
    "            data = {\n",
    "                'token': pushover_api_token,\n",
    "                'user': pushover_user_key,\n",
    "                'message': message,\n",
    "            }\n",
    "            try:\n",
    "                if image_path:\n",
    "                    files = {'attachment': open(image_path, 'rb')}\n",
    "                    response = requests.post('https://api.pushover.net/1/messages.json', data=data, files=files)\n",
    "                else:\n",
    "                    response = requests.post('https://api.pushover.net/1/messages.json', data=data)\n",
    "                print(f'Notification sent: {response.status_code}')\n",
    "            except Exception as e:\n",
    "                print(f'Failed to send notification: {e}')\n",
    "        \n",
    "        # Submit the notification task to the thread pool executor\n",
    "        self.executor.submit(send_notification)\n",
    "    \n",
    "    def stop_video_stream(self):    # Stop the video stream and release resources\n",
    "        self.running = False\n",
    "        if self.read_thread is not None:\n",
    "            self.read_thread.join()\n",
    "        if self.process_thread is not None:\n",
    "            self.process_thread.join()\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Video stream closed.\")\n",
    "\n",
    "    def read_frames(self):   # Read frames from the video stream in a loop\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()   # Read a frame from the video stream\n",
    "                if not ret:\n",
    "                    print(f\"Error: Unable to read frame from URL {self.video_url}\")\n",
    "                    break\n",
    "                with self.buffer_lock:   # Lock the buffer before modifying it\n",
    "                    if len(self.frame_buffer) < 2:\n",
    "                        self.frame_buffer.append(frame)   # Add the frame to the buffer\n",
    "                time.sleep(0.02)  # Small sleep to reduce CPU usage\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in read_frames: {e}\")\n",
    "            self.running = False\n",
    "\n",
    "    # Perform inference on the frame using the trained model\n",
    "    def perform_inference(self, frame):\n",
    "        results = train_5(frame)\n",
    "        results.render()\n",
    "        return results\n",
    "\n",
    "    # Check if the current detection is a new fire detection\n",
    "    def is_new_fire_detection(self, detection):\n",
    "        if self.last_detection is None:\n",
    "            return True\n",
    "            \n",
    "        # Check the spatial overlap and time interval\n",
    "        x1, y1, x2, y2 = detection[:4]\n",
    "        lx1, ly1, lx2, ly2, ltime = self.last_detection\n",
    "        \n",
    "        # Simple overlap check to see if the detection is within the bounds of the last detection\n",
    "        if (time.time() - ltime) > self.detection_interval:\n",
    "            return True\n",
    "        # Simple overlap check\n",
    "        if (x1 < lx2 and x2 > lx1 and y1 < ly2 and y2 > ly1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def process_frames(self):\n",
    "        try:\n",
    "            while self.running:\n",
    "                with self.buffer_lock:\n",
    "                    if len(self.frame_buffer) > 0:\n",
    "                        frame = self.frame_buffer.pop(0)            # Get a frame from the buffer\n",
    "                    else:\n",
    "                        time.sleep(0.01)\n",
    "                        continue\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert the frame to RGB\n",
    "                results = self.perform_inference(frame_rgb)         # Perform inference on the frame\n",
    "                detections = results.xyxy[0]                        # Get the detections from the results\n",
    "                high_conf_detections = [d for d in detections if d[4] > 0.40]   # Filter detections by confidence threshold\n",
    "\n",
    "                # Initialize frame_with_results to the current frame for default display\n",
    "                frame_with_results = frame_rgb.copy()\n",
    "\n",
    "                new_detection_saved = False\n",
    "                for detection in high_conf_detections:\n",
    "                    if not new_detection_saved and self.is_new_fire_detection(detection):\n",
    "                        frame_with_results = results.ims[0]\n",
    "                        current_time = time.time()\n",
    "                        timestamp = int(current_time)\n",
    "                        save_path = os.path.join(self.snapsave_dir, f'image_{timestamp}.jpg')\n",
    "                        cv2.imwrite(save_path, cv2.cvtColor(frame_with_results, cv2.COLOR_RGB2BGR))   # Save the frame with detection\n",
    "                        print(f\"New fire detected! Frame saved to {save_path}\")\n",
    "\n",
    "                        # Send Pushover notification if enabled\n",
    "                        if self.pushover_enabled:\n",
    "                            self.send_pushover_notification('High confidence detection made!', save_path)\n",
    "                            print('Alert notification sent!')\n",
    "                        \n",
    "                        self.last_saved_time = current_time  \n",
    "                        self.last_detection = (*detection[:4], current_time)   # Update the last detection details\n",
    "                        new_detection_saved = True   # Ensure only one image is saved per cycle\n",
    "                        self.last_saved_image_path = save_path\n",
    "\n",
    "                self.frame = frame_with_results   # Update the frame to be displayed\n",
    "                time.sleep(0.05)    # Small delay to control the processing speed\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in process_frames: {e}\")\n",
    "            self.running = False\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Configure GUI\n",
    "class AppGUI:\n",
    "    def __init__(self, root, bg_image_path=None):\n",
    "        self.root = root\n",
    "        self.root.title(\"FireSight Guardian\")\n",
    "\n",
    "        # Initialize video_stream_app to None\n",
    "        self.video_stream_app = None\n",
    "\n",
    "        # Configure the grid layout\n",
    "        self.root.columnconfigure(0, weight=1)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.root.columnconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(0, weight=0)\n",
    "        self.root.rowconfigure(1, weight=0)\n",
    "        self.root.rowconfigure(2, weight=1)\n",
    "        self.root.rowconfigure(3, weight=0)\n",
    "\n",
    "        # Set background image if provided\n",
    "        if bg_image_path and os.path.exists(bg_image_path):\n",
    "            self.bg_image = Image.open(bg_image_path)\n",
    "            self.bg_image = self.bg_image.resize((self.root.winfo_screenwidth(), self.root.winfo_screenheight()), Image.LANCZOS)\n",
    "            self.bg_image = self.bg_image.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "            self.bg_photo = ImageTk.PhotoImage(self.bg_image)\n",
    "            self.bg_canvas = Canvas(root, width=self.root.winfo_screenwidth(), height=self.root.winfo_screenheight())\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_image(0, 0, anchor=NW, image=self.bg_photo)\n",
    "        else:\n",
    "            self.bg_canvas = Canvas(root, width=800, height=600)\n",
    "            self.bg_canvas.grid(row=0, column=0, rowspan=4, columnspan=3)\n",
    "            self.bg_canvas.create_rectangle(0, 0, 800, 600, fill='lightblue', stipple='gray12')\n",
    "\n",
    "        # Adding a label\n",
    "        Label(root, text=\"CAM Stream URL:\", font=('Arial', 14), bg='#2a9df4').grid(row=0, column=0, padx=10, pady=10, sticky='e')\n",
    "        self.url_entry = Entry(root, width=50, font=('Arial', 14))\n",
    "        self.url_entry.grid(row=0, column=1, padx=10, pady=10, sticky='w')\n",
    "        self.url_entry.insert(0, \"http://192.168.251.70/\")\n",
    "\n",
    "        # Add start button\n",
    "        self.start_button = Button(root, text=\"Start Stream\", font=('Arial', 14), command=self.start_stream)\n",
    "        self.start_button.grid(row=1, column=0, padx=10, pady=10, sticky='e')\n",
    "\n",
    "        # Add stop button\n",
    "        self.stop_button = Button(root, text=\"Stop Stream\", font=('Arial', 14), command=self.stop_stream)\n",
    "        self.stop_button.grid(row=1, column=1, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Notification toggle switch ON/OFF\n",
    "        self.toggle_button = Button(root, text=\"Enable Notifications\", font=('Arial', 14), command=self.toggle_notifications)\n",
    "        self.toggle_button.grid(row=1, column=2, padx=10, pady=10, sticky='w')\n",
    "\n",
    "        # Preview window size for live video feed\n",
    "        self.preview_width = 580\n",
    "        self.preview_height = 360\n",
    "\n",
    "        # Create a canvas to display the live video feed\n",
    "        self.canvas = Canvas(root, width=self.preview_width, height=self.preview_height)\n",
    "        self.canvas.grid(row=2, column=0, columnspan=2, padx=10, pady=10, sticky='n')\n",
    "        self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, stipple='gray12')\n",
    "        self.no_signal_text = self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        # Frame to hold snapshots\n",
    "        self.snapshot_frame = Frame(root, width=180, height=380)\n",
    "        self.snapshot_frame.grid(row=2, column=2, padx=10, pady=10, sticky='n')\n",
    "\n",
    "        # Create a canvas within the frame to display snapshots of detected events\n",
    "        self.snapshot_canvas = Canvas(self.snapshot_frame, width=160, height=360, bg='black')\n",
    "        self.snapshot_canvas.pack(side=LEFT, fill=BOTH, expand=True)\n",
    "\n",
    "        # Add a scrollbar to navigate through snapshots\n",
    "        self.scrollbar = Scrollbar(self.snapshot_frame, orient=VERTICAL, command=self.snapshot_canvas.yview)\n",
    "        self.scrollbar.pack(side=RIGHT, fill=Y)\n",
    "\n",
    "        # Configure the canvas to work with the scrollbar\n",
    "        self.snapshot_canvas.configure(yscrollcommand=self.scrollbar.set)\n",
    "        self.snapshot_canvas.bind('<Configure>', lambda e: self.snapshot_canvas.configure(scrollregion=self.snapshot_canvas.bbox('all')))\n",
    "\n",
    "        # Create a frame inside the canvas to hold the individual snapshot images\n",
    "        self.image_frame = Frame(self.snapshot_canvas, width=160, height=360)\n",
    "        self.snapshot_canvas.create_window((0, 0), window=self.image_frame, anchor=NW)\n",
    "\n",
    "        # Create a text widget to display terminal-like output for logs and status updates\n",
    "        self.terminal_text = Text(root, width=80, height=10, bg='black', fg='green', font=('Consolas', 12))\n",
    "        self.terminal_text.grid(row=3, column=0, columnspan=3, padx=10, pady=10, sticky='n')\n",
    "        self.terminal_text.insert(tk.END, \"Terminal Output:\\n\")\n",
    "\n",
    "        # Start the video feed and update the canvas with new frames\n",
    "        self.update_video()\n",
    "\n",
    "    def start_stream(self):\n",
    "        # Configure start and stop button colors\n",
    "        self.start_button.configure(bg='green')\n",
    "        self.stop_button.configure(bg='white')\n",
    "\n",
    "        # Get video URL from the input field\n",
    "        video_url = self.url_entry.get()\n",
    "        self.video_stream_app = VideoStreamApp(video_url)\n",
    "\n",
    "        # Attempt to start the video stream, show an error if it fails\n",
    "        if not self.video_stream_app.start_video_stream():\n",
    "            messagebox.showerror(\"Error\", \"Unable to open video stream. Check the URL.\")\n",
    "\n",
    "        # Update the terminal output to indicate the stream has started\n",
    "        self.terminal_text.insert(tk.END, \"Started video stream...\\n\")\n",
    "\n",
    "    def stop_stream(self):\n",
    "        self.start_button.configure(bg='white')\n",
    "        self.stop_button.configure(bg='red')\n",
    "\n",
    "        # Stop the video stream if it is running and clean up resources\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "            self.video_stream_app = None\n",
    "\n",
    "        # Update the terminal output\n",
    "        self.terminal_text.insert(tk.END, \"Stopped video stream...\\n\")\n",
    "\n",
    "    def toggle_notifications(self):\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.pushover_enabled = not self.video_stream_app.pushover_enabled\n",
    "            if self.video_stream_app.pushover_enabled:\n",
    "                self.toggle_button.config(text=\"Disable Notifications\", bg='red')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications enabled.\\n\")\n",
    "            else:\n",
    "                self.toggle_button.config(text=\"Enable Notifications\", bg='white')\n",
    "                self.terminal_text.insert(tk.END, \"Pushover notifications disabled.\\n\")\n",
    "\n",
    "    def update_video(self):\n",
    "        # Update the canvas with the latest video frame, if available\n",
    "        if self.video_stream_app and self.video_stream_app.frame is not None:\n",
    "            self.canvas.delete(\"all\")\n",
    "            frame_rgb = self.video_stream_app.frame\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_pil = frame_pil.resize((self.preview_width, self.preview_height), Image.LANCZOS)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "        else:\n",
    "            # If no video frame is available, display \"No signal\"\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_rectangle(0, 0, self.preview_width, self.preview_height, fill='black', stipple='gray12')\n",
    "            self.canvas.create_text(self.preview_width // 2, self.preview_height // 2, text=\"No signal\", fill=\"white\", font=('Arial', 24))\n",
    "\n",
    "        # Update the snapshot preview if there is a new snapshot\n",
    "        if self.video_stream_app:\n",
    "            self.update_snapshots()\n",
    "\n",
    "        # Schedule the next frame update after 30 milliseconds\n",
    "        self.root.after(30, self.update_video)\n",
    "\n",
    "    def update_snapshots(self):\n",
    "        # Check if there is a last saved image path\n",
    "        if self.video_stream_app and self.video_stream_app.last_saved_image_path:\n",
    "            for widget in self.image_frame.winfo_children():\n",
    "                widget.destroy()\n",
    "\n",
    "            # Load and resize the latest snapshot image\n",
    "            snapshot_image = Image.open(self.video_stream_app.last_saved_image_path)\n",
    "            snapshot_image = snapshot_image.resize((160, 120), Image.LANCZOS)\n",
    "            snapshot_tk = ImageTk.PhotoImage(snapshot_image)\n",
    "\n",
    "            # Display the snapshot image in the frame\n",
    "            label = Label(self.image_frame, image=snapshot_tk)\n",
    "            label.image = snapshot_tk\n",
    "            label.pack()\n",
    "\n",
    "    def clean_up(self):\n",
    "        # Stop the video stream and close the application window when exiting\n",
    "        if self.video_stream_app:\n",
    "            self.video_stream_app.stop_video_stream()\n",
    "        self.root.destroy()\n",
    "\n",
    "# Main entry point for the application\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "    app = AppGUI(root, bg_image_path)\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", app.clean_up)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79370d-6957-48ea-8eb1-70accb8894d1",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece49f6-9e6f-4051-81f3-22d6f8553ec2",
   "metadata": {},
   "source": [
    "IP check ESP32-CAM\n",
    "\n",
    "    - Ensure CAM module is connected to the same local network as your PC\n",
    "    - Run code below to find the IP address of camera\n",
    "    - Replace IP address in above code with the correct IP found\n",
    "  \n",
    "    --> self.url_entry.insert(0, \"http://192.168.251.70/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad40ad1-c7c4-4de5-9c22-f5b0208fda3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device found: 192.168.251.57\n",
      "Device found: 192.168.251.70\n",
      "Device found: 192.168.251.223\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "import struct\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def get_ip():\n",
    "    hostname = socket.gethostname()\n",
    "    ip_address = socket.gethostbyname(hostname)\n",
    "    return ip_address\n",
    "\n",
    "def ping_ip(ip):\n",
    "    param = '-n' if platform.system().lower() == 'windows' else '-c'\n",
    "    command = ['ping', param, '1', ip]\n",
    "    response = os.popen(' '.join(command)).read()\n",
    "    if \"TTL\" in response:\n",
    "        print(f\"Device found: {ip}\")\n",
    "\n",
    "def scan_network():\n",
    "    ip_parts = get_ip().split('.')\n",
    "    base_ip = '.'.join(ip_parts[:3]) + '.'\n",
    "\n",
    "    threads = []\n",
    "    for i in range(1, 255):\n",
    "        ip = base_ip + str(i)\n",
    "        thread = threading.Thread(target=ping_ip, args=(ip,))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        time.sleep(0.01)  # Small delay to prevent overwhelming the network\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scan_network()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
